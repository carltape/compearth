%  dvips -t letter specfem.dvi -o specfem.ps ; ps2pdf specfem.ps
%  pdflatex specfem.tex

\documentclass[10pt,fleqn,letterpaper]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{latexsym}
\usepackage[round]{natbib}
\usepackage{xspace}
\usepackage{graphicx}
\usepackage{xcolor,listings}

%\usepackage{fancyhdr}
%\pagestyle{fancy}

%=====================================================
%       SPACING COMMANDS (Latex Companion, p. 52)
%=====================================================

\usepackage{setspace}

\usepackage[margin=1in]{geometry}

%\include{NEWCOMMANDS}

\graphicspath{
  {figures/}
}

\newcommand{\thetitle}{SPECFEM3D Tutorial for 2013 CIG-QUEST-IRIS Workshop}
\newcommand{\theauthor}{Carl, Qinya, Elliott, Emanuele}
\title{\thetitle}
\author{\theauthor}
\date{Last compiled: \today}

\usepackage[bookmarks=true,colorlinks=true,%
            pdftitle={\thetitle},%
            pdfauthor={\theauthor}%
           ]{hyperref}

\definecolor{codebg}{RGB}{238,238,238}
\definecolor{codeframe}{RGB}{204,204,204}
\lstset{
  language=bash,
  basicstyle=\small\ttfamily,
  breakatwhitespace=true,
  breaklines=true,
  prebreak=\raisebox{0ex}[0ex][0ex]{%
    \ensuremath{\rightharpoondown}},
  postbreak=\raisebox{0ex}[0ex][0ex]{%
    \ensuremath{\hookrightarrow\space}},
  escapechar=\@,
  backgroundcolor=\color{codebg},
  frame=single,
  framesep=10pt,
  rulecolor=\color{codeframe}
}

%=====================================================
\begin{document}
%=====================================================

\maketitle

%=====================================================

%\tableofcontents

\subsection*{Overview}

%--------------

\subsection*{Log-in instructions}

\begin{enumerate}
\item get account info from ARSC
\item ssh into ARSC (is X11 okay from mac?)
\item Explain text editing (vi, gedit, emacs)
\end{enumerate}

%---------------

\subsection*{Step-by-step instructions, example 1: homogeneous halfspace synthetic seismograms}

The purpose of this example is to step through all the key steps of \verb+SPECFEM3D+: get the code, configure the code for your cluster, generate a mesh using (GEO)CUBIT, partition the mesh, generate databases, run the solver, and check the output. The example is trivial, but it is important to remember that 

\begin{enumerate}
\item check what modules are loaded by default
\begin{lstlisting}
$ module list
Currently Loaded Modulefiles:
  1) pgi/13.4                2) openmpi-pgi-13.4/1.4.3
  3) netcdf/4.3.0.pgi-13.4   4) PrgEnv-pgi/13.4
\end{lstlisting}

\item Check out two copies\footnote{There's no need for two copies, but this will make it a bit easier to keep track of the different exampled.} of SPECFEM3D version 22719 from the code repository at CIG (\url{http://www.geodynamics.org/})
%
\begin{lstlisting}
$ svn co -r 22719 http://geodynamics.org/svn/cig/seismo/3D/SPECFEM3D/trunk SPECFEM3D_22719_default
$ svn co -r 22719 http://geodynamics.org/svn/cig/seismo/3D/SPECFEM3D/trunk SPECFEM3D_22719_socal
\end{lstlisting}
%
(This may take a few minutes.)

\item check version info
%
\begin{lstlisting}
$ cd SPECFEM3D_22719_default
$ svn info
Path: .
URL: http://geodynamics.org/svn/cig/seismo/3D/SPECFEM3D/trunk
Repository Root: http://geodynamics.org/svn/cig
Repository UUID: 42e91aa9-f6fe-0310-9bd8-dd834c9eb30a
Revision: 22728
Node Kind: directory
Schedule: normal
Last Changed Author: danielpeter
Last Changed Rev: 22719
Last Changed Date: 2013-08-20 06:16:30 -0800 (Tue, 20 Aug 2013)
\end{lstlisting}

The {\em base directory} for the code is \verb+SPECFEM3D_22719_default+, which we will call \verb+SPECFEM3D+ in the instructions.

\item Take a quick look at the user manual, mainly as a reminder to come back to it for details.
%
\begin{lstlisting}
$ evince doc/USER_MANUAL/manual_SPECFEM3D_Cartesian.pdf &
\end{lstlisting}

\item Check that all software is available (or that modules are loaded):
\begin{lstlisting}
$ which mpirun # OpenMPI
$ which cubit  # Cubit
$ which python # Python
\end{lstlisting}

\item Configure package, e.g. using the portland compiler:
\begin{lstlisting}
$ ./configure F90=pgf90 MPIFC=mpif90
\end{lstlisting}

If successful, this will generate several \verb+Makefile+s in \verb+src/+, as well as \verb+shared/constants.h+ and \verb+shared/precision.h+, among others.

\item Adapt the run scripts for your cluster and your example run.

- copy run scripts from \verb+utils/Cluster/+ into \verb+SPECFEM3D/+, e.g.,
\begin{lstlisting}
$ cd utils/Cluster/pbs/
$ cp go_decomposer_pbs.bash go_generate_databases_pbs.bash go_solver_pbs.bash ../../../
$ cd ../../../
\end{lstlisting}

Set all bash scripts to run in the \verb+standard+ queue (in general, the queue will depend on your specific cluster) by editing the line
\begin{lstlisting}
#PBS -q standard
\end{lstlisting}
(The default simulation time and number of cores is okay for this example.)
 
\item The rest of the instructions follow from the homogeneous halfspace example here
\begin{lstlisting}
SPECFEM3D/examples/homogeneous_halfspace/README
\end{lstlisting}

Copy the input files from examples directory into \verb+SPECFEM3D/DATA/+
\begin{lstlisting}
$ cd examples/homogeneous_halfspace/DATA/
$ cp * ../../../DATA/
\end{lstlisting}
%
Note that only three input files are required: for the source (\verb+CMTSOLUTION+), for the stations (\verb+STATIONS+), and for the simulation parameters (\verb+Par_file+).

\item create mesh:

From the directory \verb+SPECFEM3D/examples/homogeneous_halfspace+, open the cubit GUI, \verb+claro+:
\begin{lstlisting}
$ claro
\end{lstlisting}
%
(Close the ``Tip of the Day''.)
To ensure that the path is local, \verb+File --> Set Directory+, then click \verb+Choose+.

Run the meshing script: from the Menu bar, select \verb+Tools -> Play Journal File+, set \verb+Files of Type+ to \verb+All Files+, then select \verb+block_mesh.py+.

If everything goes fine, this creates the ten mesh files in subdirectory \verb+MESH/+:
\begin{lstlisting}
$ ls MESH
MESH/absorbing_surface_file_bottom
MESH/absorbing_surface_file_xmax
MESH/absorbing_surface_file_xmin
MESH/absorbing_surface_file_ymax
MESH/absorbing_surface_file_ymin
MESH/free_surface_file
MESH/materials_file
MESH/mesh_file
MESH/nodes_coords_file
MESH/nummaterial_velocity_file
\end{lstlisting}

You should be able to translate, rotate, and zoom on the mesh using a three-button mouse. (This can be emulated if you set X11 preferences, then (on a Mac) hold the \verb+control+, \verb+alt+, or \verb+command+ buttons while clicking and moving the mouse.)

The cubit graphics window should show a mesh similar to the file
\begin{verbatim}
picture_of_this_homogeneous_regular_mesh.png
\end{verbatim}

\item decompose mesh files:

Compile the decomposer in directory \verb+SPECFEM3D/+:
\begin{lstlisting}
$ make xdecompose_mesh
\end{lstlisting}
%
This will compile the partitioner \verb+SCOTCH+.

Then run the decomposer:
\begin{lstlisting}
$ qsub go_decomposer_pbs.bash
\end{lstlisting}
%
You can check the status of the job with the command
%
\begin{lstlisting}
$ qmap | grep USERNAME
\end{lstlisting}
%
The job should take 20 seconds or so. It creates the four mesh partitions \verb+proc000***_Database+ in the directory \verb+OUTPUT_FILES/DATABASES_MPI/+. The output file \verb+OUTPUT_FILES/*.o+ contains information on the partitioning.

\item generate databases:

Compile \verb+generate_databases+ in the directory \verb+SPECFEM3D/+:
\begin{lstlisting}
$ make xgenerate_databases
\end{lstlisting}
Submit the job:
\begin{lstlisting}
$ qsub go_generate_databases_pbs.bash
\end{lstlisting}

The job should take about a minute.
It creates binary mesh files, e.g. \verb+proc000***_external_mesh.bin+ in the directory \verb+OUTPUT_FILES/DATABASES_MPI/+.

It is a good idea to look at the partitions of the mesh files. Load some vtk files (e.g., vs) into paraview:
\begin{lstlisting}
$ cd OUTPUT_FILES/DATABASES_MPI/
$ module load paraview
$ paraview
\end{lstlisting}
%
Then \verb+File --> Open+, and select all four \verb+vs*vtk+ files. When you are done, be sure to unload the \verb+paraview+ module, since here it was compiled with \verb+gnu+, which conflicts with the \verb+portland+ we are using.
%
\begin{lstlisting}
$ module unload paraview
$ cd ../../
\end{lstlisting}

\item run simulation:

   - compile specfem3D (from \verb+SPECFEM3D/+:
\begin{lstlisting}
$ make xspecfem3D
\end{lstlisting}
   - submit script to run solver:
\begin{lstlisting}
$ qsub go_solver_pbs.bash
\end{lstlisting}

The simulation runs on 4 cores and should take about 30 minutes. You can track the progress with the timestamp files generated in \verb+OUTPUT_FILES/+ (type \verb+ls -ltr+ to see the most recent files). When the job is complete, you should have 3 sets (semd,semv,sema) of 12 (\verb+ls -1 *semd | wc+) seismogram files in the directory \verb+OUTPUT_FILES+, as well as 51 \verb+timestamp******+ files.

\item Compare your computed seismograms with the reference seismograms.

A quick visual comparison can be done from \verb+SPECFEM3D/+ using \verb+xmgrace+:
\begin{lstlisting}
$ module load grace
$ xmgrace examples/homogeneous_halfspace/REF_SEIS/*Z.semd &
$ xmgrace OUTPUT_FILES/*Z.semd &
\end{lstlisting}

\end{enumerate}

%===============================================================================

\subsection*{Step-by-step instructions, example 2: homogeneous halfspace sensitivity kernel}

\begin{enumerate}
\item QINYA'S INSTRUCTIONS HERE -- note that there are some new scripts added (by Daniel?)
\end{enumerate}

%===============================================================================

\subsection*{Step-by-step instructions, example 3: southern California}

This example is at a scale that will likely not run on a single laptop or desktop computer. In other words, the required memory must be distributed over a number of different machines in order to run the simulation. Here we use 96 cores of the cluster.

\begin{enumerate}
\item Copy bash scripts into the base directory:

\begin{lstlisting}
$ cd SPECFEM3D_22719_socal
$ cp ../SPECFEM3D_22719_default/*bash .
\end{lstlisting}

\item configure
\begin{lstlisting}
$ ./configure F90=pgf90 MPIFC=mpif90
\end{lstlisting}

\item compile all
\begin{lstlisting}
$ make all
\end{lstlisting}

\item Link the mesh directory as an example
\begin{lstlisting}
$ cd examples
$ ln -s /import/c/d/ERTHQUAK/GEOCUBIT_MESH/socal_med400km .
\end{lstlisting}

\item Modify \verb+go_decomposer_pbs.bash+ to point to the new directory:
\begin{lstlisting}
MESHDIR=examples/socal_med400km/MESH/
\end{lstlisting}

\item Link the tomography file and copy input files
\begin{lstlisting}
$ cd DATA
$ ln -s /import/c/d/ERTHQUAK/MODEL/cvm119_1000_1000_0250_741_549.xyz tomography_model.xyz
$ cp ../examples/socal_med400km/in_data_files/* .
\end{lstlisting}

\item modify \verb+go_generate_databases_pbs.bash+ and \verb+go_solver_pbs.bash+ to have the proper time limits and number of cores
\begin{lstlisting}
#PBS -l nodes=6:ppn=16,walltime=1:00:00
#PBS -q standard
\end{lstlisting}

%\item delete the empty directory
%
%\begin{lstlisting}
%rm -rf OUTPUT_FILES/DATABASES_MPI
%\end{lstlisting}
%
%This simulation will create a directory \verb+DATABASES_socal_med400km+ that is outside of \verb+OUTPUT_FILES+. This is useful% since we may have many simulations associated with the same mesh.

\item Follow the same steps as in Example 1: decompose, generate databases, solver. Here the programs have all been compiled, so only submitting the run scripts is needed. (But wait for each one to finish, and check the output before proceeding to the next step.)
%
\begin{itemize}
\item The decomposer takes about 3 minutes.
\item The generate databases takes about 15 minutes.
\item The solver takes about 25 minutes.
\end{itemize}
%
The simulation runs on 96 cores and should take about 25 minutes. You can track the progress with the timestamp files generated in \verb+OUTPUT_FILES/+ (type \verb+ls -ltr+ to see the most recent files). When the job is complete, you should have 3 sets (semd,semv,sema) of 1107 (\verb+ls -1 *semd | wc+) seismogram files in the directory \verb+OUTPUT_FILES+, as well as 4 \verb+timestamp******+ files.

As expected, the seismograms contain numerical noise, since the source half duration in \verb+CMTSOLUTION+ was set to 0~s. This allows for maximal flexibility in post-processing, since the seismograms can be convolved with any source time function (see manual). However, it is important to know what the minimum resolving period of a particular mesh and model is, since this provides a guide for how to filter the seismograms in post-processing.

\item Now make a change to one of the input files in \verb+SPECFEM3D/DATA/+, either \verb+Par_file+, \verb+CMTSOLUTION+, or \verb+STATIONS+. Rename the \verb+OUTPUT_FILES+ directory if you do not want to over-write your previous output. Then submit the new job. (Note that no recompilation is needed.)

\end{enumerate}

%===============================================================================

\subsection*{Step-by-step instructions, example 4: GPU}

In this example, we show how \verb+SPECFEM3D+ can be used on a GPU cluster.

\begin{enumerate}
\item ELLIOTT'S INSTRUCTIONS HERE (start with login to fish)
\end{enumerate}

%=====================================================
% REFERENCES

%\begin{spacing}{1.0}
%\bibliographystyle{agu08}
%\bibliography{preamble,REFERENCES,refs_carl,refs_socal,refs_source}
%\end{spacing}

%=====================================================
\end{document}
%=====================================================
